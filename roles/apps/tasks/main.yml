---
# ---------- Paquetes base ----------
- name: Instalar paquetes base
  apt:
    name: "{{ apt_base_packages }}"
    update_cache: yes
  become: yes

- name: Instalar unclutter (oculta cursor inactivo)
  apt:
    name: unclutter
    state: present
    update_cache: yes
  become: yes

# Lo esencial para pantalla:
- name: Paquetes base de display (x11/xset)
  apt:
    name:
      - x11-xserver-utils
    state: present
    update_cache: yes
  become: yes

# CEC opcional: intenta instalar y si falla, no rompas el play
- name: Instalar cec-utils (opcional)
  apt:
    name: cec-utils
    state: present
    update_cache: yes
  become: yes
  ignore_errors: yes
  register: cec_install

- name: Aviso cec-utils no se pudo instalar, se deja opcional
  debug:
    msg: "cec-utils falló por dependencias (mezcla de versiones). Seguimos sin CEC."
  when: cec_install is failed

# ---------- Directorios ----------
- name: Crear directorios base
  file:
    path: "{{ item }}"
    state: directory
    owner: "{{ kiosk_user }}"
    group: "{{ kiosk_user }}"
    mode: "0755"
  loop:
    - "{{ electron_root }}"
    - "{{ signage_root }}"
  become: yes

# --- SSH keys en el target ---
- name: Crear ~/.ssh
  file:
    path: "/home/{{ kiosk_user }}/.ssh"
    state: directory
    owner: "{{ kiosk_user }}"
    group: "{{ kiosk_user }}"
    mode: "0700"
  become: yes

- name: Copiar llave electron
  copy:
    src: "{{ playbook_dir }}/secrets/id_ed25519_electron"
    dest: "/home/{{ kiosk_user }}/.ssh/id_ed25519_electron"
    mode: "0600"
    owner: "{{ kiosk_user }}"
    group: "{{ kiosk_user }}"
  become: yes
  no_log: true

- name: Copiar llave signage
  copy:
    src: "{{ playbook_dir }}/secrets/id_ed25519_signage"
    dest: "/home/{{ kiosk_user }}/.ssh/id_ed25519_signage"
    mode: "0600"
    owner: "{{ kiosk_user }}"
    group: "{{ kiosk_user }}"
  become: yes
  no_log: true

- name: Asegurar known_hosts (GitHub)
  known_hosts:
    name: github.com
    key: "{{ lookup('pipe', 'ssh-keyscan -t rsa,ecdsa,ed25519 github.com') }}"
    path: "/home/{{ kiosk_user }}/.ssh/known_hosts"
    state: present
  become: yes
  become_user: "{{ kiosk_user }}"

- name: Configurar ~/.ssh/config (default + alias github-signage)
  blockinfile:
    path: "/home/{{ kiosk_user }}/.ssh/config"
    create: yes
    owner: "{{ kiosk_user }}"
    group: "{{ kiosk_user }}"
    mode: "0600"
    block: |
      Host github.com
        HostName github.com
        User git
        IdentityFile ~/.ssh/id_ed25519_electron
        IdentitiesOnly yes
        StrictHostKeyChecking accept-new

      # Usa este alias solo si el remoto de signage es git@github-signage:...
      Host github-signage
        HostName github.com
        User git
        IdentityFile ~/.ssh/id_ed25519_signage
        IdentitiesOnly yes
        StrictHostKeyChecking accept-new
  become: yes

# Solo si tu remoto de signage usa git@github-signage:...
- name: Config ~/.ssh/config con alias github-signage
  blockinfile:
    path: "/home/{{ kiosk_user }}/.ssh/config"
    create: yes
    owner: "{{ kiosk_user }}"
    group: "{{ kiosk_user }}"
    mode: "0600"
    block: |
      Host github.com
        User git
        IdentityFile ~/.ssh/id_ed25519_electron
        IdentitiesOnly yes

      Host github-signage
        HostName github.com
        User git
        IdentityFile ~/.ssh/id_ed25519_signage
        IdentitiesOnly yes
  when: electron_repo is search('github-signage') or signage_repo is search('github-signage')
  become: yes

# ---------- Clonar/actualizar repos ----------
- name: Clonar/actualizar electron_rasp
  git:
    repo: "{{ electron_repo }}"
    dest: "{{ electron_root }}/electron_rasp"
    version: "{{ electron_branch }}"
    force: yes
    accept_hostkey: yes
    key_file: "/home/{{ kiosk_user }}/.ssh/id_ed25519_electron"
  become: yes
  become_user: "{{ kiosk_user }}"

- name: Clonar/actualizar signage
  git:
    repo: "{{ signage_repo }}"
    dest: "{{ signage_root }}/signage"
    version: "{{ signage_branch }}"
    force: yes
    accept_hostkey: yes
    key_file: "/home/{{ kiosk_user }}/.ssh/id_ed25519_signage"
  become: yes
  become_user: "{{ kiosk_user }}"

# ---------- Python venv + requirements ----------
- name: Crear venv (si no existe)
  command: "{{ python_bin }} -m venv {{ venv_dir }}"
  args: { creates: "{{ venv_dir }}/bin/activate" }
  become: yes
  become_user: "{{ kiosk_user }}"

- name: Instalar requirements (Flask)
  command: "{{ venv_dir }}/bin/pip install --upgrade -r {{ requirements_file }}"
  become: yes
  become_user: "{{ kiosk_user }}"

# ---------- NPM para Electron ----------
- name: Instalar dependencias npm (electron)
  command: npm ci
  args:
    chdir: "{{ electron_app_dir }}"
  become: yes
  become_user: "{{ kiosk_user }}"

# ---------- Scripts de auto-pull (copiados 1:1 de tu Pi) ----------
- name: Instalar update_repo.sh (electron)
  copy:
    src: update_repo.sh
    dest: "{{ electron_root }}/update_repo.sh"
    mode: "0755"
    owner: "{{ kiosk_user }}"
    group: "{{ kiosk_user }}"
  become: yes

- name: Instalar signage update.sh
  copy:
    src: signage_update.sh
    dest: "{{ signage_root }}/signage/update.sh"
    mode: "0755"
    owner: "{{ kiosk_user }}"
    group: "{{ kiosk_user }}"
  become: yes

# ---------- systemd: services/timers ----------
- name: electron_rasp-electron.service
  template:
    src: electron_rasp-electron.service.j2
    dest: /etc/systemd/system/electron_rasp-electron.service
    mode: "0644"
  notify: [reload systemd]
  become: yes

- name: Crear dir para drop-ins de electron
  file:
    path: /etc/systemd/system/electron_rasp-electron.service.d
    state: directory
    mode: "0755"
  become: yes

- name: Drop-in override (CPU + flags)
  template:
    src: electron_rasp-electron.override.conf.j2
    dest: /etc/systemd/system/electron_rasp-electron.service.d/override.conf
    mode: "0644"
  notify: [reload systemd]
  become: yes

- name: electron_rasp-flask.service
  template:
    src: electron_rasp-flask.service.j2
    dest: /etc/systemd/system/electron_rasp-flask.service
    mode: "0644"
  notify: [reload systemd]
  become: yes

- name: electron_rasp-update.service
  template:
    src: electron_rasp-update.service.j2
    dest: /etc/systemd/system/electron_rasp-update.service
    mode: "0644"
  notify: [reload systemd]
  become: yes

- name: electron_rasp-update.timer
  template:
    src: electron_rasp-update.timer.j2
    dest: /etc/systemd/system/electron_rasp-update.timer
    mode: "0644"
  notify: [reload systemd]
  become: yes

- name: signage-update.service
  template:
    src: signage-update.service.j2
    dest: /etc/systemd/system/signage-update.service
    mode: "0644"
  notify: [reload systemd]
  become: yes

- name: signage-update.timer
  template:
    src: signage-update.timer.j2
    dest: /etc/systemd/system/signage-update.timer
    mode: "0644"
  notify: [reload systemd]
  become: yes

- name: Habilitar y arrancar servicios/timers
  systemd:
    name: "{{ item }}"
    enabled: yes
    state: started
  loop:
    - electron_rasp-flask.service
    - electron_rasp-electron.service
    - electron_rasp-update.timer
    - signage-update.timer
  become: yes

# ---------- LightDM autologin (opcional) ----------
- name: Configurar autologin en LightDM (opcional)
  ini_file:
    path: /etc/lightdm/lightdm.conf
    section: "Seat:*"
    option: "{{ item.option }}"
    value: "{{ item.value }}"
    no_extra_spaces: true
    backup: yes
  loop:
    - { option: "autologin-user",   value: "{{ lightdm_autologin_user }}" }
    - { option: "autologin-session", value: "{{ lightdm_session }}" }
    - { option: "user-session",      value: "{{ lightdm_session }}" }
    - { option: "xserver-command",   value: "X" }
  when: manage_lightdm
  become: yes

- name: Habilitar lightdm (display manager)
  systemd:
    name: lightdm.service
    enabled: yes
    state: started
  when: manage_lightdm
  become: yes

- name: Crear carpeta de autostart del usuario
  file:
    path: "/home/{{ kiosk_user }}/.config/lxsession/{{ lightdm_session }}"
    state: directory
    owner: "{{ kiosk_user }}"
    group: "{{ kiosk_user }}"
    mode: "0755"
  become: yes

- name: Autostart LXDE sin DPMS
  copy:
    dest: "/home/{{ kiosk_user }}/.config/lxsession/{{ lightdm_session }}/autostart"
    owner: "{{ kiosk_user }}"
    group: "{{ kiosk_user }}"
    mode: "0644"
    content: |
      @xset s off
      @xset -dpms
      @xset s noblank
      @unclutter -idle 0.5 -root
  become: yes

# --- TeamViewer: autostart GUI robusto (LXDE + XDG) ---
- name: TeamViewer | detectar binario
  shell: command -v teamviewer
  register: tv_bin
  changed_when: false
  failed_when: false
  become: yes

- name: TeamViewer | definir sesiones LXDE a cubrir
  set_fact:
    lxde_sessions_all: "{{ ([lightdm_session] if manage_lightdm else []) + ['LXDE-pi', 'LXDE'] | unique }}"

- name: TeamViewer | preparar carpetas de autostart LXDE
  file:
    path: "/home/{{ kiosk_user }}/.config/lxsession/{{ item }}"
    state: directory
    owner: "{{ kiosk_user }}"
    group: "{{ kiosk_user }}"
    mode: "0755"
  loop: "{{ lxde_sessions_all }}"
  when: tv_bin.rc == 0
  become: yes

- name: TeamViewer | añadir línea de autostart en LXDE
  lineinfile:
    path: "/home/{{ kiosk_user }}/.config/lxsession/{{ item }}/autostart"
    insertafter: EOF
    line: "@teamviewer --minimized"
    create: yes
    owner: "{{ kiosk_user }}"
    group: "{{ kiosk_user }}"
    mode: "0644"
  loop: "{{ lxde_sessions_all }}"
  when: tv_bin.rc == 0
  become: yes

- name: TeamViewer | carpeta XDG autostart
  file:
    path: "/home/{{ kiosk_user }}/.config/autostart"
    state: directory
    owner: "{{ kiosk_user }}"
    group: "{{ kiosk_user }}"
    mode: "0755"
  when: tv_bin.rc == 0
  become: yes

- name: TeamViewer | .desktop XDG
  copy:
    dest: "/home/{{ kiosk_user }}/.config/autostart/teamviewer.desktop"
    owner: "{{ kiosk_user }}"
    group: "{{ kiosk_user }}"
    mode: "0644"
    content: |
      [Desktop Entry]
      Type=Application
      Name=TeamViewer
      Exec=teamviewer --minimized
      X-GNOME-Autostart-enabled=true
      X-LXDE-Session=true
  when: tv_bin.rc == 0
  become: yes

# --- TeamViewer: daemon robusto + diagnóstico ---
- name: TeamViewer | facts de servicios
  service_facts:

- name: TeamViewer | marcar si el service existe
  set_fact:
    tv_service_present: "{{ 'teamviewerd.service' in (ansible_facts.services | default({})) }}"

# Si no existe el unit, muestra pista (no rompe el play)
- name: TeamViewer | aviso si no hay service (¿instalado?)
  debug:
    msg:
      - "No se encontró teamviewerd.service en systemd."
      - "Si TeamViewer no está instalado, instala 'teamviewer' o 'teamviewer-host'."
  when: not tv_service_present

# Quitar hard-mask si existiera
- name: TeamViewer | detectar hard-mask
  stat:
    path: "/etc/systemd/system/teamviewerd.service"
  register: tvd_unit
  when: tv_service_present
  become: yes

- name: TeamViewer | eliminar hard-mask
  file:
    path: "/etc/systemd/system/teamviewerd.service"
    state: absent
  when:
    - tv_service_present
    - tvd_unit.stat.islnk is defined
    - tvd_unit.stat.islnk
    - tvd_unit.stat.lnk_target == '/dev/null'
  become: yes

# Drop-in: arrancar tras red y reintentar si cae
- name: TeamViewer | crear carpeta de drop-ins
  file:
    path: /etc/systemd/system/teamviewerd.service.d
    state: directory
    mode: "0755"
  when: tv_service_present
  become: yes

- name: TeamViewer | override (Restart + After network-online)
  copy:
    dest: /etc/systemd/system/teamviewerd.service.d/override.conf
    mode: "0644"
    content: |
      [Unit]
      Wants=network-online.target
      After=network-online.target

      [Service]
      Restart=on-failure
      RestartSec=3s
  when: tv_service_present
  notify: reload systemd
  become: yes

- name: TeamViewer | daemon-reload
  systemd:
    daemon_reload: yes
  when: tv_service_present
  become: yes

# Enable+start por systemd
- name: TeamViewer | enable/start (systemd)
  systemd:
    name: teamviewerd.service
    masked: no
    enabled: yes
    state: started
  register: tv_systemd
  failed_when: false
  when: tv_service_present
  become: yes

# Compat CLI (sirve en varias versiones)
- name: TeamViewer | enable daemon (CLI compat)
  command: teamviewer --daemon enable
  register: tv_enable_cli
  changed_when: "'Enabling' in tv_enable_cli.stdout or tv_enable_cli.rc == 0"
  failed_when: false
  when: tv_bin.rc == 0
  become: yes

- name: TeamViewer | start daemon (CLI compat)
  command: teamviewer --daemon start
  register: tv_start_cli
  changed_when: "'Starting' in tv_start_cli.stdout or tv_start_cli.rc == 0"
  failed_when: false
  when: tv_bin.rc == 0
  become: yes

# Espera activa (si hay unit)
- name: TeamViewer | esperar ACTIVE
  shell: "systemctl is-active teamviewerd.service"
  register: tv_active
  retries: 10
  delay: 2
  until: tv_active.rc == 0
  changed_when: false
  failed_when: false
  when: tv_service_present
  become: yes

# Si NO quedó activo, volcar status y journal (diagnóstico en output)
- name: TeamViewer | volcado de estado y logs si falla
  shell: |
    set -o pipefail
    systemctl status teamviewerd.service --no-pager -l || true
    echo '--- Últimas 120 líneas de journal ---'
    journalctl -u teamviewerd.service -n 120 --no-pager || true
  register: tv_diag
  changed_when: false
  failed_when: false
  when:
    - tv_service_present
    - tv_active is defined
    - tv_active.rc != 0
  become: yes

- name: TeamViewer | info (si hay binario)
  command: teamviewer info
  register: tv_info
  changed_when: false
  failed_when: false
  when: tv_bin.rc == 0
  become: yes

- name: TeamViewer | resumen
  debug:
    msg:
      - "systemd enable/start intentado: {{ tv_service_present }}"
      - "CLI enable rc={{ tv_enable_cli.rc | default('n/a') }}, start rc={{ tv_start_cli.rc | default('n/a') }}"
      - "is-active rc={{ tv_active.rc | default('n/a') }}, salida={{ tv_active.stdout | default('') }}"
      - "teamviewer info:"
      - "{{ tv_info.stdout_lines | default([]) }}"
      - "diagnóstico (si falló):"
      - "{{ tv_diag.stdout_lines | default([]) }}"